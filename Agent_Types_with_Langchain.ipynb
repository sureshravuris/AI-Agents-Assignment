{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UtpKlSwiE6VQ",
        "outputId": "3861ede3-ed33-4aa5-cfc3-3e197301478e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain-openai\n",
            "  Downloading langchain_openai-0.1.1-py3-none-any.whl (32 kB)\n",
            "Collecting langchain-core<0.2.0,>=0.1.33 (from langchain-openai)\n",
            "  Downloading langchain_core-0.1.35-py3-none-any.whl (273 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m273.0/273.0 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting openai<2.0.0,>=1.10.0 (from langchain-openai)\n",
            "  Downloading openai-1.14.3-py3-none-any.whl (262 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m262.9/262.9 kB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tiktoken<1,>=0.5.2 (from langchain-openai)\n",
            "  Downloading tiktoken-0.6.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m21.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.33->langchain-openai) (6.0.1)\n",
            "Collecting jsonpatch<2.0,>=1.33 (from langchain-core<0.2.0,>=0.1.33->langchain-openai)\n",
            "  Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
            "Collecting langsmith<0.2.0,>=0.1.0 (from langchain-core<0.2.0,>=0.1.33->langchain-openai)\n",
            "  Downloading langsmith-0.1.33-py3-none-any.whl (86 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.6/86.6 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting packaging<24.0,>=23.2 (from langchain-core<0.2.0,>=0.1.33->langchain-openai)\n",
            "  Downloading packaging-23.2-py3-none-any.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.0/53.0 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.33->langchain-openai) (2.6.4)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.33->langchain-openai) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.33->langchain-openai) (8.2.3)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.10.0->langchain-openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai<2.0.0,>=1.10.0->langchain-openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai<2.0.0,>=1.10.0->langchain-openai)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.10.0->langchain-openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.10.0->langchain-openai) (4.66.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.10.0->langchain-openai) (4.10.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken<1,>=0.5.2->langchain-openai) (2023.12.25)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.10.0->langchain-openai) (3.6)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.10.0->langchain-openai) (1.2.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.10.0->langchain-openai) (2024.2.2)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai<2.0.0,>=1.10.0->langchain-openai)\n",
            "  Downloading httpcore-1.0.4-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.8/77.8 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.10.0->langchain-openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain-core<0.2.0,>=0.1.33->langchain-openai)\n",
            "  Downloading jsonpointer-2.4-py2.py3-none-any.whl (7.8 kB)\n",
            "Collecting orjson<4.0.0,>=3.9.14 (from langsmith<0.2.0,>=0.1.0->langchain-core<0.2.0,>=0.1.33->langchain-openai)\n",
            "  Downloading orjson-3.9.15-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (138 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.5/138.5 kB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain-core<0.2.0,>=0.1.33->langchain-openai) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain-core<0.2.0,>=0.1.33->langchain-openai) (2.16.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-core<0.2.0,>=0.1.33->langchain-openai) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-core<0.2.0,>=0.1.33->langchain-openai) (2.0.7)\n",
            "Installing collected packages: packaging, orjson, jsonpointer, h11, tiktoken, jsonpatch, httpcore, langsmith, httpx, openai, langchain-core, langchain-openai\n",
            "  Attempting uninstall: packaging\n",
            "    Found existing installation: packaging 24.0\n",
            "    Uninstalling packaging-24.0:\n",
            "      Successfully uninstalled packaging-24.0\n",
            "Successfully installed h11-0.14.0 httpcore-1.0.4 httpx-0.27.0 jsonpatch-1.33 jsonpointer-2.4 langchain-core-0.1.35 langchain-openai-0.1.1 langsmith-0.1.33 openai-1.14.3 orjson-3.9.15 packaging-23.2 tiktoken-0.6.0\n"
          ]
        }
      ],
      "source": [
        "%pip install langchain-openai"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Creating a Simple Chatbot using OpenAI**"
      ],
      "metadata": {
        "id": "0Cy_N0NfFWTH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from google.colab import userdata\n",
        "\n",
        "api_key = userdata.get('MyAPI_Key')\n",
        "\n",
        "# Creating a basic chatbot\n",
        "llm_chatbot = ChatOpenAI(openai_api_key=api_key)\n",
        "\n",
        "prompt_chatbot = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", \"You are a friendly and informative chatbot.\"),\n",
        "    (\"user\", \"{input}\")\n",
        "])\n",
        "\n",
        "chatbot_chain = prompt_chatbot | llm_chatbot | StrOutputParser()\n",
        "\n",
        "# Example usage\n",
        "response_chatbot = chatbot_chain.invoke({\"input\": \"Give me an exercise schedule for a complete beginner for a week\"})\n",
        "print(response_chatbot)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ye1UH0UEFTP2",
        "outputId": "1afb7117-d97d-404f-b862-5caa6839ef92"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sure! Here's a sample exercise schedule for a complete beginner for a week:\n",
            "\n",
            "Day 1: \n",
            "- 20 minutes of brisk walking or jogging\n",
            "- 10 minutes of stretching exercises\n",
            "\n",
            "Day 2:\n",
            "- 15 minutes of bodyweight exercises (such as squats, lunges, push-ups, and planks)\n",
            "- 10 minutes of stretching exercises\n",
            "\n",
            "Day 3:\n",
            "- Rest day or light activity such as gentle yoga or a short walk\n",
            "\n",
            "Day 4:\n",
            "- 20 minutes of cycling or using a stationary bike\n",
            "- 10 minutes of stretching exercises\n",
            "\n",
            "Day 5:\n",
            "- 15 minutes of bodyweight exercises (such as crunches, leg raises, and tricep dips)\n",
            "- 10 minutes of stretching exercises\n",
            "\n",
            "Day 6:\n",
            "- 20 minutes of a low-impact workout like swimming or dancing\n",
            "- 10 minutes of stretching exercises\n",
            "\n",
            "Day 7:\n",
            "- Rest day or light activity such as a leisurely bike ride or a nature walk\n",
            "\n",
            "Remember to listen to your body and take rest when needed. It's important to gradually increase the intensity and duration of your workouts as you progress. Make sure to stay hydrated, eat nutritious meals, and get plenty of rest to support your exercise routine.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Summarization Agent with Langchain:**\n",
        "\n",
        "\n",
        "- **Retrieve API Key:** Use Google Colab's userdata (assuming it's a hypothetical module) to securely fetch the OpenAI API key.\n",
        "\n",
        "- **Initialize LLM Agent:** Create an instance of ChatOpenAI with the OpenAI API key for interaction with the model.\n",
        "\n",
        "- **Define Prompt Template:** Specify the task for the LLM using ChatPromptTemplate, setting it up as a summarization agent with a clear instruction that it should condense English text into a concise summary.\n",
        "\n",
        "- **Chain Components:** Combine the defined prompt template with the LLM agent and a string output parser (StrOutputParser) to form a processing chain. This chain takes an input, sends it through the LLM with the given prompt, and parses the output as a string.\n",
        "\n",
        "- **Invoke Chain with Input:** Execute the summarization chain with a piece of long text as input to receive a concise summary as output."
      ],
      "metadata": {
        "id": "dEEQkDPZLjwg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from google.colab import userdata\n",
        "\n",
        "\n",
        "api_key = userdata.get('MyAPI_Key')\n",
        "\n",
        "# Creating a summarization agent\n",
        "llm_summarizer = ChatOpenAI(openai_api_key=api_key)\n",
        "\n",
        "prompt_summarizer = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", \"You are a summarization agent that condenses long English text into a concise summary.\"),\n",
        "    (\"user\", \"{input}\")\n",
        "])\n",
        "\n",
        "summarization_chain = prompt_summarizer | llm_summarizer | StrOutputParser()\n",
        "\n",
        "# Example usage\n",
        "long_text = \"\"\"\n",
        "The history of natural language processing (NLP) began in the 1950s, as a pioneering area at the intersection of computer science, artificial intelligence, and linguistics. The goal was to create software that could interpret and generate human languages naturally. Over the decades, NLP has evolved significantly with the advent of machine learning and deep learning, leading to the development of sophisticated models capable of understanding, generating, and translating languages with remarkable accuracy. This evolution has enabled a wide range of applications, from automated translation services to intelligent personal assistants and beyond.\n",
        "\"\"\"\n",
        "response_summarizer = summarization_chain.invoke({\"input\": long_text})\n",
        "print(response_summarizer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mMd2TCcdLw4U",
        "outputId": "ae8aa6cc-8ffb-44c7-f36d-5d6bf87c874f"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The history of natural language processing (NLP) started in the 1950s, aiming to develop software that could understand and generate human languages. Over time, NLP has advanced through machine learning and deep learning, resulting in sophisticated models for language tasks. These developments have led to various applications like translation services and personal assistants.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Medicine Prescribing Agent with Langchain:**\n",
        "\n",
        "For demonstration purposes only, here's how you could structure such an agent hypothetically using langchain_openai and langchain_core, emphasizing that this should not be used for actual medical advice or prescriptions:\n",
        "\n",
        "\n",
        "- **Initialize LLM Agent for Medical Prescriptions:** Set up an instance of ChatOpenAI with the OpenAI API key for processing medical information.\n",
        "\n",
        "- **Define Medical Prescribing Prompt Template:** Create a task-specific prompt with instructions for the LLM to act as a medicine prescribing agent, considering symptoms and conditions described in the input.\n",
        "\n",
        "- **Chain Components Together:** Link the medical prescribing prompt template with the LLM agent and a string output parser to form a complete processing chain.\n",
        "\n",
        "- **Invoke with Medical Scenario:** Pass a medical scenario as input to receive hypothetical medicine recommendations.\n",
        "\n",
        "Here's a hypothetical code outline:"
      ],
      "metadata": {
        "id": "RLHFJlwxOtyE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from google.colab import userdata\n",
        "\n",
        "api_key = userdata.get('MyAPI_Key')  # Secure API key retrieval\n",
        "llm_prescriber = ChatOpenAI(openai_api_key=api_key)  # Medical LLM agent\n",
        "\n",
        "# Define the task for the LLM as a medicine prescribing agent\n",
        "prompt_prescriber = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", \"You are a highly knowledgeable medicine prescribing agent. Provide prescription advice based on symptoms described.\"),\n",
        "    (\"user\", \"{input}\")\n",
        "])\n",
        "\n",
        "# Processing chain\n",
        "prescribing_chain = prompt_prescriber | llm_prescriber | StrOutputParser()\n",
        "\n",
        "# Example usage with a hypothetical scenario\n",
        "medical_scenario = \"The patient is experiencing severe seasonal allergies with symptoms including sneezing, nasal congestion, and itchy eyes.\"\n",
        "response_prescriber = prescribing_chain.invoke({\"input\": medical_scenario})\n",
        "print(response_prescriber)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f5qVTQUKOM3R",
        "outputId": "250497eb-96bf-4b79-f271-a0bb6f5e94ea"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Based on the symptoms described, I recommend the patient try an over-the-counter antihistamine such as loratadine, cetirizine, or fexofenadine to help with the sneezing, nasal congestion, and itchy eyes associated with seasonal allergies. Additionally, using a saline nasal spray may help alleviate nasal congestion. If symptoms persist or worsen, it would be best for the patient to consult with a healthcare provider for further evaluation and prescription medication options.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Important Notes:**\n",
        "\n",
        "**Not for Medical Use:** This example is purely hypothetical and should not be used for actual medical diagnostics or prescriptions. Real-world medical prescribing systems require rigorous validation, regulatory approval, and oversight by medical professionals."
      ],
      "metadata": {
        "id": "olaK8V67PQXc"
      }
    }
  ]
}